
# CHAI Weather Data Platform â€“ Technical Assessment

Author: Emmanuel BAMBANZA
Role: Data Engineer, Tech Advisor CHAI, Assessment
Tech Stack: Python, Airflow, Docker, PostgreSQL, Metabase

Overview

This project implements a mini end-to-end data platform for CHAIâ€™s technical assessment.
It ingests live weather data from the Open-Meteo API for multiple Rwandan cities, cleans
and transforms it, loads it into a PostgreSQL warehouse, and exposes a simple visualization
dashboard via Metabase.

The solution includes:

â€¢ Automated ETL Pipeline (Python + Docker)
â€¢ Airflow Orchestrated DAG (daily schedule)
â€¢ PostgreSQL Warehouse (staging + mart layers)
â€¢ Data Enrichment using local city metadata (population + area)
â€¢ Metabase Dashboard (auto-configured)
â€¢ Fully reproducible Docker Compose environment

                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Open-Meteo APIâ”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚  Ingest
                             â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  pipeline/ingest.py â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Clean/Enrich
                             â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  pipeline/transform.py â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Load to DB
                             â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ pipeline/model.py       â”‚
                  â”‚  - staging_weather      â”‚
                  â”‚  - mart_daily_city_*    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Orchestrate
                             â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   Airflow   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Query
                             â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Metabase   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


chaid_assessment/

 â”œâ”€â”€ airflow/                  # Airflow configs, logs excluded via .gitignore
 â”œâ”€â”€ airflow/dags/             # weather_etl_pipeline DAG
 â”œâ”€â”€ pipeline/
 â”‚    â”œâ”€â”€ ingest.py            # API ingestion
 â”‚    â”œâ”€â”€ transform.py         # cleaning + CSV output
 â”‚    â”œâ”€â”€ model.py             # load to DB + aggregation
 â”‚    â””â”€â”€ run_pipeline.py      # CLI runner
 â”œâ”€â”€ db/init.sql               # PostgreSQL schema creation
 â”œâ”€â”€ data/raw/                 # raw CSV (generated)
 â”œâ”€â”€ data/processed/           # cleaned CSV (generated)
 â”œâ”€â”€ metabase-data/            # local config (ignored)
 â”œâ”€â”€ metabase-init/            # automated Metabase setup
 â”œâ”€â”€ docker-compose.yml        # full platform stack
 â”œâ”€â”€ Dockerfile                # pipeline image
 â”œâ”€â”€ Dockerfile.airflow        # Airflow custom build
 â””â”€â”€ README.md

ğŸš€ Running the Entire Platform
1. Clone the repository
git clone https://github.com/bambanza/chai_assessment.git
cd chai_assessment


Start the platform
docker compose up --build


This will automatically start:

Service	Description
postgres	Data warehouse
pipeline	One-off ingestion + transformation run
airflow	Webserver + scheduler
metabase	Dashboard UI
metabase-init	Automatically configures Metabase
3. Access Services
Component	URL
Airflow UI	http://localhost:8080

Metabase Dashboard	http://localhost:3000

Airflow Login:

username: admin
password: admin


Metabase is auto-initialized by metabase-init.

ğŸ§ª Features Implemented
âœ” Multi-City weather ingestion

Cities include:

Kigali

Musanze

Huye

âœ” Raw â†’ Clean â†’ Warehouse flow

Stages:

Raw CSV: data/raw/weather_raw.csv

Clean CSV: data/processed/weather_clean.csv

Staging Table: staging_weather

Mart Table: mart_daily_city_weather

âœ” Enrichment using external CSV

data/raw/cities.csv includes:

city

population

area_km2

This is joined into the mart layer.

âœ” Airflow DAG

DAG ID: weather_etl_pipeline

Pipeline:

ingest_weather  â†’  transform_weather  â†’  model_weather


Runs daily.

âœ” Metabase Dashboard

Auto-created on startup:

Temperature & humidity tables

City-level daily aggregates

Population vs temperature insight

ğŸ¤ Notes for Reviewer

No secrets are included; all connection strings use local service names.

Logs and metabase database are excluded from Git thanks to .gitignore.

Everything is fully reproducible with a single command.
